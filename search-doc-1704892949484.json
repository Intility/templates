{"searchDocs":[{"title":".NET Templates","type":0,"sectionRef":"#","url":"/dotnet/","content":"","keywords":"","version":"Next"},{"title":"Recommended reading​","type":1,"pageTitle":".NET Templates","url":"/dotnet/#recommended-reading","content":"Tutorial: Create a web API with ASP.NET CoreASP.NET Core fundamentalsIntility Template Source ","version":"Next","tagName":"h3"},{"title":"Adding Environments","type":0,"sectionRef":"#","url":"/dotnet/advanced/adding-environments","content":"","keywords":"","version":"Next"},{"title":"Enabling the deploy:prod job​","type":1,"pageTitle":"Adding Environments","url":"/dotnet/advanced/adding-environments#enabling-the-deployprod-job","content":"The provided deploy:prod job is disabled by default. This is to force you to make an active choice on wether you want to use the job or ArgoCD. To enable the job, simply remove the . from the last job. .gitlab-ci.yml - .deploy:prod: + deploy:prod:  ","version":"Next","tagName":"h2"},{"title":"Trigger production jobs​","type":1,"pageTitle":"Adding Environments","url":"/dotnet/advanced/adding-environments#trigger-production-jobs","content":"First, we have to update the appVersion field in our Helm charts Chart.yaml. chart/Chart.yaml appVersion: &quot;x.x.x&quot;  Then, we have to create a git tag and push it git tag x.x.x git push --tags  After all the other jobs has completed, we can manually trigger the deploy:prod job. This is manual by design, and shouldn't be set to automatic. ","version":"Next","tagName":"h3"},{"title":"Separate OpenShift project​","type":1,"pageTitle":"Adding Environments","url":"/dotnet/advanced/adding-environments#separate-openshift-project","content":"You can, and should create a separate OpenShift project to host the production environment. To do this, simply follow the same steps as earlier. This time, name it aa-&lt;project-slug&gt;-prod. When adding the OPENSHIFT_TOKEN to CI/CD variables, select Production as the Environment scope. This variable will then be used instead of the default one in the deploy:prod job.  note If you can't see the Production environment when creating a variable, you need to trigger the production jobs first. The image:prod job will then provision the Production environment, and you can insert the OPENSHIFT_TOKEN before triggering the deploy job. ","version":"Next","tagName":"h3"},{"title":"Adding even more Environments​","type":1,"pageTitle":"Adding Environments","url":"/dotnet/advanced/adding-environments#adding-even-more-environments","content":"Usually, a development and a production environment is enough. In big applications however, you might see the need for more environments. In this example, we will set up a QA environment. To do this, we will simply copy the prod jobs, and create our own for qa instead. .gitlab-ci.yml image:qa: extends: image:dev variables: IMAGE_TAG: qa environment: name: QA rules: - if: '$CI_COMMIT_TAG' .deploy:qa: extends: deploy:dev variables: ROUTE: $CI_PROJECT_NAME-qa.apps.int.intility.no environment: name: QA url: https://$CI_PROJECT_NAME-qa.apps.int.intility.no rules: - if: '$CI_COMMIT_TAG' needs: [ &quot;test&quot;, &quot;image:qa&quot; ]  note We don't override the image version to avoid version collisions with the production jobs. This example will, like the production jobs, be triggered by git tags. But it will automatically deploy it to the QA environment, which will be created in the default OpenShift project, unless you've created a custom QA project. ","version":"Next","tagName":"h2"},{"title":"Features","type":0,"sectionRef":"#","url":"/dotnet/features","content":"Features The template is packed with already made decisions, so you don't have to make them. These solutions are a culmination of many years of managing services in production and aims to target established in-house infrastructure. note The templates are updated as the technology and infrastructure changes over time. Helm chartProject debug settingsSwagger configurationDockerfilesREADME templateGitLab CI/CD pipelineAPI VersioningLogging configurationTelemetry instrumentation","keywords":"","version":"Next"},{"title":"Deploy with ArgoCD","type":0,"sectionRef":"#","url":"/dotnet/advanced/deploy-argocd","content":"Deploy with ArgoCD info This page isn't finished yet. If you are comfortable with this subject, feel free to contribute.","keywords":"","version":"Next"},{"title":"Installation","type":0,"sectionRef":"#","url":"/dotnet/installation","content":"","keywords":"","version":"Next"},{"title":"Bootstrap new project using the template​","type":1,"pageTitle":"Installation","url":"/dotnet/installation#bootstrap-new-project-using-the-template","content":"You can either use the dotnet new command or Visual Studio -&gt; New Project wizard to create a new project based on the templates. dotnet CLIVisual Studio note If you only want to create a project, and skip creating a solution, use the --project argument. # create project with solution dotnet new iwebapi -o MyService # create project only dotnet new iwebapi -o MyService --project # run project cd MyService dotnet run --project MyService/MyService.csproj  ","version":"Next","tagName":"h2"},{"title":"Updating the template​","type":1,"pageTitle":"Installation","url":"/dotnet/installation#updating-the-template","content":"danger Earlier versions of the CLI had troubles updating packages due to long-lived caches. You need to be on version 5.0.301 or higher for updating to work properly. note This will not update already bootstrapped projects. Check for updates by running dotnet new --update-check  If there are any updates available, update with dotnet new --update-apply  or dotnet new --install Intility.Templates  ","version":"Next","tagName":"h2"},{"title":"GitLab Repository","type":0,"sectionRef":"#","url":"/dotnet/setup/gitlab","content":"","keywords":"","version":"Next"},{"title":"Pushing your application​","type":1,"pageTitle":"GitLab Repository","url":"/dotnet/setup/gitlab#pushing-your-application","content":"Creating a dotnet project from a template does not automatically create a git repository for you, so we have to make one ourselves. Follow the &quot;Push an existing folder&quot; example, which should look something like this: git init git remote add origin git@gitlab.intility.no:Group/intility-api.git git add . git commit -m &quot;Initial commit&quot; git push -u origin main  The pipeline will fail initially, but don't worry, we'll set it up correctly in the next steps. ","version":"Next","tagName":"h2"},{"title":"Add GitLab Deploy Token​","type":1,"pageTitle":"GitLab Repository","url":"/dotnet/setup/gitlab#add-gitlab-deploy-token","content":"The pipeline publishes a docker image to GitLab Container Registry, and uses Helm to create resources in OpenShift. As a result, OpenShift needs access to pull images from GCR. In your GitLab repository, go to Settings -&gt; Repository -&gt; Deploy tokens. Create a new token named gitlab-deploy-token, and give it the read_registry scope.  That's all you have to do in the repository. The token is exposed as a variable in the pipeline, and helm applies it as a pull secret in OpenShift. Read more about GitLab deploy tokens here. ","version":"Next","tagName":"h2"},{"title":"Adding CI/CD Variables​","type":1,"pageTitle":"GitLab Repository","url":"/dotnet/setup/gitlab#adding-cicd-variables","content":"In your project on GitLab, go to Settings -&gt; CI / CD, and expand the Variables section. We don't need to add anything yet, but it's here we'll add tokens and such in the other steps. ","version":"Next","tagName":"h2"},{"title":"Adding Badges​","type":1,"pageTitle":"GitLab Repository","url":"/dotnet/setup/gitlab#adding-badges","content":"In your project on GitLab, go to Settings -&gt; General, and expand the Badges section. Here you can add badges by giving them a Name, Link and Image URL.  We can go ahead and add a badge for our pipeline with the following values: Name: Pipeline Link: https://gitlab.intility.com/%{project_path} Image URL: https://gitlab.intility.com/%{project_path}/badges/%{default_branch}/pipeline.svg ","version":"Next","tagName":"h2"},{"title":"AAD Authorization","type":0,"sectionRef":"#","url":"/dotnet/setup/authorization","content":"","keywords":"","version":"Next"},{"title":"API​","type":1,"pageTitle":"AAD Authorization","url":"/dotnet/setup/authorization#api","content":"Head over to Azure -&gt; Azure Active Directory -&gt; App registrationswith your Intility Account, and create a new registration.  Select a fitting name for your project, this name will be presented to the user during consent. Under Supported account types, choose either Intility AS only - Single tenant or Any Azure AD directory - Multitenant. This can be changed later, so if you're unsure what to choose, select single tenant. Leave the Redirect URI section blank. Hit the register button, and you will be taken to an overview of your newly created registration.  Copy the Application (Client) ID GUID, and paste it into the AzureAd:ClientId field in your appsettings.json file. appsettings.json { &quot;AzureAd&quot;: { &quot;ClientId&quot;: &quot;YOUR_CLIENT_ID&quot;, ... }, ... }  info If you chose Multitenant, set the AzureAd:TenantId field to common. ","version":"Next","tagName":"h3"},{"title":"Add an application scope​","type":1,"pageTitle":"AAD Authorization","url":"/dotnet/setup/authorization#add-an-application-scope","content":"Go to Expose an API in your app registration, and add a scope. You will be prompted to set an Application ID URI. Use the suggested one, and hit Save and continue.  Add a scope named user_impersonation, that can be consented by Admins and users. You can use the following descriptions: Access API as user Allows the app to access the API as the user. Access API as you Allows the app to acces the API as you.  ","version":"Next","tagName":"h3"},{"title":"Swagger​","type":1,"pageTitle":"AAD Authorization","url":"/dotnet/setup/authorization#swagger","content":"In addition to creating an App Registration for the API itself, we need to make one for the Swagger client too. Again head over to Azure -&gt; Azure Active Directory -&gt; App registrations.  Use the same name appended with Swagger. Under Redirect URI, select Single-page application (SPA) and enter http://localhost:5000/oauth2-redirect.html. Hit the register button, and you will be taken to an overview of your newly created registration.  Copy the Application (Client) ID GUID, and paste it into the AzureAd:ClientId field in your appsettings.json file. appsettings.json { &quot;Swagger&quot;: { &quot;ClientId&quot;: &quot;YOUR_SWAGGER_CLIENT_ID&quot;, ... }, ... }  ","version":"Next","tagName":"h2"},{"title":"Adding reply URLs​","type":1,"pageTitle":"AAD Authorization","url":"/dotnet/setup/authorization#adding-reply-urls","content":"For each deployment of your app, you'll need to register it. You can do that by going to the Authentication page.  The first reply URLs we need to add are the localhost https URL, and the OpenShift deploy URL: https://localhost:5001/oauth2-redirect.html https://{your-project-slug}-dev.apps.int.intility.no/oauth2-redirect.html  You can also add more later if you create more environments. ","version":"Next","tagName":"h3"},{"title":"Access API​","type":1,"pageTitle":"AAD Authorization","url":"/dotnet/setup/authorization#access-api","content":"To allow Swagger to talk to the API, you need to add API permissions to the Swagger app registration. Go to API permissions, and hit Add a permission. Under My APIs, find your API, select the scope(s) and press Add permissions.  ","version":"Next","tagName":"h3"},{"title":"Guest users​","type":1,"pageTitle":"AAD Authorization","url":"/dotnet/setup/authorization#guest-users","content":"The template comes with an authorization policy that denies guest users in Azure AD from accessing the API. This policy is enabled when the application is not set up as multitenant. If you want guest users to access your single tenant API, simply remove the lines applying the policy. Startup.cs services.AddAuthorization(options =&gt; { var tenantId = Configuration[&quot;AzureAd:TenantId&quot;]; if (tenantId != &quot;common&quot; &amp;&amp; tenantId != &quot;organizations&quot;) { options.AddPolicy(&quot;NoGuests&quot;, policy =&gt; policy.RequireClaim( ClaimConstants.TenantId, tenantId)); } });  ","version":"Next","tagName":"h2"},{"title":"User Assignment in Enterprise Application​","type":1,"pageTitle":"AAD Authorization","url":"/dotnet/setup/authorization#user-assignment-in-enterprise-application","content":"The policy successfully denies guest users access to the API. However, it's not very user friendly, since the user won't know their denied until they call the API. Using user assignment in Enterprise Applications, we can deny users during authentication. Go to Azure AD -&gt; Enterprise Applications and find your application (you can search by Client ID). Under Properties, enable User assignment required? and save.  Then, go to Users and groups, and add user/group. Find users or a fitting group and assign it to the role Default Access. note Groups you select should have all users as direct members of the group. Nested groups does not work with Enterprise Applications. This should be done for all app registrations (API, Swagger and frontend). For more information, check out our internal docs. ","version":"Next","tagName":"h3"},{"title":"Azure App Config","type":0,"sectionRef":"#","url":"/dotnet/advanced/azure-app-config","content":"","keywords":"","version":"Next"},{"title":"Create App Configuration​","type":1,"pageTitle":"Azure App Config","url":"/dotnet/advanced/azure-app-config#create-app-configuration","content":"In Azure, create an App Configuration, and go to it.  Copy the endpoint URL, and paste it into the AppConfig field in Properties/launchSettings.json. Properties/launchSettings.json { &quot;profiles&quot;: { &quot;YOUR_PROJECT_NAME&quot;: { ... &quot;environmentVariables&quot;: { &quot;AppConfig&quot;: &quot;MY_APP_CONFIG_ENDPOINT&quot; } } ... } }  The template is set up to use built-in credentials of your development machine. This means that we need to allow your (or more) accounts to access the App Configuration. Go to Access Control (IAM) in the sidebar, then click Add and Add role assignment. Select App Configuration Data Owner, and your own account or a group.  info If you do not have access to add role assignments, you should as someone with the role assignment Owner to do it for you. You can now add Key-values in Configuration manager, and they will be applied to your local development environment. ","version":"Next","tagName":"h2"},{"title":"Create Key Vault​","type":1,"pageTitle":"Azure App Config","url":"/dotnet/advanced/azure-app-config#create-key-vault","content":"In Azure, create a Key Vault. When setting up access policies, allow the same group/users you set up in your App Configuration to Get and List the Keys and Secrets. You can now add Key Vault references in the App Configurations Configuration manager, and they will be applied to your local development environment. ","version":"Next","tagName":"h2"},{"title":"Use in development deployment​","type":1,"pageTitle":"Azure App Config","url":"/dotnet/advanced/azure-app-config#use-in-development-deployment","content":"Since the config uses your machines credentials to access the App Configuration and Key Vault, it won't automatically work with your development deployment. To set this up, we need to grant your App Registration we set up earlier access to the App Configuration and Key Vault. First, give it the App Configuration Data Reader role in the App Configuration. Then, give it Get and List permissions for Key and Secrets. You also need a client secret for your App Registration, create one in Azure AD -&gt; App Registrations -&gt; Your App Registration -&gt; Certificates &amp; secrets. Set up the following variables in GitLab CI/CD under the Development environment scope AppConfig: The App Configuration endpointAZURE_CLIENT_ID: The App Registration client idAZURE_CLIENT_SECRET: The client secret you just madeAZURE_TENANT_ID: The tenant id of your App Registration (check in your App Registrations Overview) Lastly, we need to configure the development deployment to use these variables. We do this by passing the variables we just set up to Helm: .gitlab-ci.yml deploy:dev: ... script: - oc login $OPENSHIFT_SERVER --token=$OPENSHIFT_TOKEN - helm upgrade --install $CI_ENVIRONMENT_SLUG ./Company.WebApplication1/chart --set nameOverride=$CI_PROJECT_NAME --set image.repository=$CI_REGISTRY_IMAGE --set image.tag=$IMAGE_TAG --set registry.url=$CI_REGISTRY --set registry.user=$CI_DEPLOY_USER --set registry.password=$CI_DEPLOY_PASSWORD --set route=$ROUTE --set replicaCount=2 --set secrets.Sentry__Dsn=$SENTRY_DSN --set config.ASPNETCORE_ENVIRONMENT=$CI_ENVIRONMENT_NAME --set config.AppConfig=$AppConfig --set config.AZURE_CLIENT_ID=$AZURE_CLIENT_ID --set config.AZURE_CLIENT_SECRET=$AZURE_CLIENT_SECRET --set config.AZURE_TENANT_ID=$AZURE_TENANT_ID  The development environment will now be able to connect and use the configuration from the App Registration and Key vault. note Don't worry, even though the deploy:prod job extends the deploy:dev job, the variables won't be set, since we only scoped them to the Development environment. ","version":"Next","tagName":"h2"},{"title":"Deploy","type":0,"sectionRef":"#","url":"/dotnet/setup/deploy","content":"","keywords":"","version":"Next"},{"title":"Create project​","type":1,"pageTitle":"Deploy","url":"/dotnet/setup/deploy#create-project","content":"UICLI Go to our OpenShift instance and log in as Intility Developer. Create a project, the name should be aa-&lt;GITLAB_SLUG&gt;-dev, e.g. aa-my-api-dev. Add a fitting display name and description if you feel like it. ","version":"Next","tagName":"h2"},{"title":"Acquire Token​","type":1,"pageTitle":"Deploy","url":"/dotnet/setup/deploy#acquire-token","content":"UICLI In your newly created project, switch from Developer to Administrator view in the sidebar. Then go to User Management -&gt; Service Accounts, and click Create Service Account. Change the name field to gitlab-builder. After creating the Service Account, go to User Mangement -&gt; Role Bindings, and click Create Binding. Fill the form with the following values: Role Binding Name: gitlab-builder-edit Role Name: edit Subject: Service Account Subject Name: gitlab-builder After creating the role binding, go back to Service Accounts and go to the gitlab-builder Service Account. At the bottom of page, you'll find a link to a secret named gitlab-builder-token-*, click it. Copy the token field at the bottom of the page, and add it to GitLab CI/CD variables with the key OPENSHIFT_TOKEN. ","version":"Next","tagName":"h2"},{"title":"Sentry","type":0,"sectionRef":"#","url":"/dotnet/setup/sentry","content":"","keywords":"","version":"Next"},{"title":"Create Project​","type":1,"pageTitle":"Sentry","url":"/dotnet/setup/sentry#create-project","content":"Head over to the Create a new Project page in Sentry.  Under platform, select .NET.  For the project name, use the project slug from GitLab. Select a fitting team, or create a new one, and hit Create. You'll be taken to a Configure .NET page. In the code examples, copy the DSN value passed to Sentry.Init, and add it to GitLab CI/CD variables with the key SENTRY_DSN. ","version":"Next","tagName":"h2"},{"title":".gitlab-ci.yml Overview","type":0,"sectionRef":"#","url":"/dotnet/setup/gitlab-ci","content":"","keywords":"","version":"Next"},{"title":"Jobs​","type":1,"pageTitle":".gitlab-ci.yml Overview","url":"/dotnet/setup/gitlab-ci#jobs","content":"info The image:dev and image:prod jobs is set to run on pushes to master or main branch. info The image:prod and deploy:prod jobs are set to run when tags are pushed to the repository. ","version":"Next","tagName":"h2"},{"title":"build​","type":1,"pageTitle":".gitlab-ci.yml Overview","url":"/dotnet/setup/gitlab-ci#build","content":"Builds the project, and creates a build artifact for later stages to use. ","version":"Next","tagName":"h3"},{"title":"test​","type":1,"pageTitle":".gitlab-ci.yml Overview","url":"/dotnet/setup/gitlab-ci#test","content":"Runs the tests in the project. Runs parallel with build. ","version":"Next","tagName":"h3"},{"title":"image​","type":1,"pageTitle":".gitlab-ci.yml Overview","url":"/dotnet/setup/gitlab-ci#image","content":"Uses the artifact from the build step, and creates and publish a docker image with the Dockerfile.CI file using kaniko. Runs once the build job has finished. ","version":"Next","tagName":"h3"},{"title":"deploy​","type":1,"pageTitle":".gitlab-ci.yml Overview","url":"/dotnet/setup/gitlab-ci#deploy","content":"Deploys the application to OpenShift using the Helm chart. Runs once the image and test jobs have succeeded. ","version":"Next","tagName":"h3"},{"title":"Debugging the pipeline​","type":1,"pageTitle":".gitlab-ci.yml Overview","url":"/dotnet/setup/gitlab-ci#debugging-the-pipeline","content":"","version":"Next","tagName":"h2"},{"title":"Paths​","type":1,"pageTitle":".gitlab-ci.yml Overview","url":"/dotnet/setup/gitlab-ci#paths","content":"Ensure the paths used are right. In the build step, we need to ensure that we are working from the right folder. .gitlab-ci.yml build: script: - dotnet restore - cd YOUR_PROJECT_FOLDER # cd to the project folder - dotnet publish -o build artifacts: paths: - YOUR_PROJECT_FOLDER/build # the build in the project folder  In image:dev, we need the context parameter to be set to the project folder. .gitlab-ci.yml image:dev: script: - echo ... - /kaniko/executor --context $CI_PROJECT_DIR/YOUR_PROJECT_FOLDER # sets the context to your project folder  In deploy:dev, ensure the path to the chart is right. .gitlab-ci.yml deploy:dev: script: - oc login $OPENSHIFT_SERVER --token=$OPENSHIFT_TOKEN - helm upgrade --install $CI_ENVIRONMENT_SLUG ./YOUR_PROJECT_FOLDER/chart # path to chart  ","version":"Next","tagName":"h3"},{"title":"FastAPI Template","type":0,"sectionRef":"#","url":"/fastapi/","content":"FastAPI Template This FastAPI template is intended for you to get a good baseline for creating your FastAPI applications, with Azure AD authentication and authorization. The template has a lot of batteries included, such as pre-commit, project structure, example tests and options to use SQLModel and mypy. Before attempting to use this template, it is highly recommended you do the official tutorial. If you've created APIs in other Python web frameworks, FastAPI differs from the others by: FastAPI is built on starlette, so it's async firstAPI first, MVC second OpenAPI (aka Swagger) documentation are automatically generated! Fully type annotated, and types are used on runtimeFastAPI has very few batteries included (compared to e.g. Django). That's where this template is handy.","keywords":"","version":"Next"},{"title":"Included Dependencies","type":0,"sectionRef":"#","url":"/fastapi/getting-started/included-dependencies","content":"","keywords":"","version":"Next"},{"title":"fastapi-azure-auth​","type":1,"pageTitle":"Included Dependencies","url":"/fastapi/getting-started/included-dependencies#fastapi-azure-auth","content":"Docs Included for projects that select FastAPI Azure Auth (default) as their authentication strategy. This project is written and maintained by Intility. ","version":"Next","tagName":"h2"},{"title":"sentry-sdk​","type":1,"pageTitle":"Included Dependencies","url":"/fastapi/getting-started/included-dependencies#sentry-sdk","content":"Docs Used for error reporting to Sentry. ","version":"Next","tagName":"h2"},{"title":"pre-commit​","type":1,"pageTitle":"Included Dependencies","url":"/fastapi/getting-started/included-dependencies#pre-commit","content":"Docs Pre-commit is a code-checker that will run every time you attempt to commit any changes. It runs different programs, such as .flake8, black etc., all of which can be configured individually through either config files or the pyproject.toml. pre-commit When pre-commit changes something, you must add the modified file before you rerun pre-commit. It only runs on files staged for commit. ","version":"Next","tagName":"h2"},{"title":"flake8​","type":1,"pageTitle":"Included Dependencies","url":"/fastapi/getting-started/included-dependencies#flake8","content":"Docs Static code analysis which looks for different things, such as leftover print statements etc. ","version":"Next","tagName":"h2"},{"title":"black​","type":1,"pageTitle":"Included Dependencies","url":"/fastapi/getting-started/included-dependencies#black","content":"Docs Formats your code. Configuration is limited but can be found in pyproject.toml. ","version":"Next","tagName":"h2"},{"title":"Project Overview","type":0,"sectionRef":"#","url":"/fastapi/getting-started/project-overview","content":"Project Overview Depending on which template you chose, your project structure will look more or less like the following: # __init__.py files has been removed from this visualization ├── alembic.ini # Configuration for your migrations ├── app # This is where your FastAPI lives │ ├── api # APIs and routes │ │ ├── api_v1 │ │ │ ├── api.py # API routes │ │ │ ├── endpoints # Yor API endpoints │ │ │ └── └── views.py # Example APIs, based on your options │ │ ├── dependencies.py # Dependencies for your application │ │ └── security.py # Security for your application, such as Azure AD authentication │ ├── core │ │ ├── db.py # Database engine is configured here │ │ └── config.py # All your application settings, such as secrets and passwords │ ├── main.py # FastAPI is configured here. │ ├── models # Database models │ │ └── cars.py │ └── schemas # Pydantic models │ └── hello_world.py ├── ci │ └── docker │ └── fastapi │ ├── Dockerfile │ ├── entrypoint.sh # Called when your Docker container is started │ └── gunicorn.conf.py # Basic gunicorn config ├── docker-compose.yaml ├── migrations # Autogenerated migrations are put here │ ├── alembic_functions.py │ ├── env.py # Environment for migrations. You should import your models here. │ ├── README # Read it, seriously. :) │ ├── script.py.mako │ └── versions │ └── d8ba1a4996fa_init.py # This is the first migration file ├── mypy.ini # mypy configuration files ├── poetry.lock # Autogenerated file for poetry ├── pyproject.toml # Your poetry configuration, such as dependencies ├── pytest.ini # Settings for all your tests └── tests # All tests are put here ├── api │ ├── auth_utils.py │ ├── conftest.py │ ├── test_api_with_auth.py │ └── test_cars_api.py ├── conftest.py # Shared utilities for your tests ├── models │ └── test_cars.py └── README.md # Read this too :) ","keywords":"","version":"Next"},{"title":"Installation","type":0,"sectionRef":"#","url":"/fastapi/getting-started/installation","content":"","keywords":"","version":"Next"},{"title":"Prerequisites​","type":1,"pageTitle":"Installation","url":"/fastapi/getting-started/installation#prerequisites","content":"Some experience with PythonPython3.9+PoetryDocker and Docker ComposeGit ","version":"Next","tagName":"h2"},{"title":"Intility Cruft​","type":1,"pageTitle":"Installation","url":"/fastapi/getting-started/installation#intility-cruft","content":"You'll need cruft in order to use this template. python -m pip install cruft  cruft cruft is a templating language built on top of cookiecutter, which uses jinja templates. ","version":"Next","tagName":"h3"},{"title":"Create FastAPI App​","type":1,"pageTitle":"Installation","url":"/fastapi/getting-started/installation#create-fastapi-app","content":"Use cruft to start your project. python -m cruft create https://github.com/Intility/templates.git --directory=&quot;fastapi&quot;  A few questions you will be prompted, here with a more verbose description: full_name: Required for pyproject.tomlemail: Required for pyproject.tomlproject_name: The folder name, and required for pyproject.toml. Keep it short and simple!description: Required for pyproject.tomlsqlmodel: An ORM for FastAPI. Select 1 if you need a database. This will create example APIs, install alembic for migrations, add postgres to the docker-compose file etc.authentication_strategy: Every API must have authentication through Azure AD, but which strategy you chose is up to you. The options are: FastAPI Azure Auth (default): Authentication and authorization is done in your FastAPI application. This is the default and recommended authentication strategy, which this tutorial will assume you chose. Under the hood, this uses fastapi-azure-auth, a library written and maintained by Intility.Kong (no auth included): The alternative is to use Kong. This removes all authentication from your FastAPI application, and assume you host your application behind Kong. This tutorial will not cover this strategy. include_example_apis: Chose whether you want example APIs and tests to be included in the generated files. If this is the first time using this template, select true. You'll now have a new folder, matching your project_name. ","version":"Next","tagName":"h2"},{"title":"Logging","type":0,"sectionRef":"#","url":"/dotnet/topics/logging","content":"","keywords":"","version":"Next"},{"title":"Configuration","type":0,"sectionRef":"#","url":"/dotnet/topics/configuration","content":"","keywords":"","version":"Next"},{"title":"Azure AD Authentication​","type":1,"pageTitle":"Configuration","url":"/dotnet/topics/configuration#azure-ad-authentication","content":" ⚠️ TODO: App RegistrationsThe relationship between SPA App, Resource App How to configure them properly  { &quot;AzureAd&quot;: { // azure identity platform instance (should not be changed) &quot;Instance&quot;: &quot;https://login.microsoftonline.com/&quot;, // primary domain of your tenant &quot;Domain&quot;: &quot;intility.onmicrosoft.com&quot;, // tenant / directory id &quot;TenantId&quot;: &quot;9b5ff18e-53c0-45a2-8bc2-9c0c8f60b2c6&quot;, // client id of your azure appReg &quot;ClientId&quot;: &quot;11111111-1111-1111-11111111111111111&quot; } }  ","version":"Next","tagName":"h2"},{"title":"Swagger​","type":1,"pageTitle":"Configuration","url":"/dotnet/topics/configuration#swagger","content":" ⚠️ TODO: Swagger authenticationSwagger versioning relationship with API versioning  { &quot;Swagger&quot;: { // Name of the service in Swagger definition and UI &quot;AppName&quot;: &quot;Company.WebApplication1 Swagger&quot;, // The client id to authenticate with. This should be an // app registration with delegated permission to the API registration &quot;ClientId&quot;: &quot;22222222-2222-2222-22222222222222222&quot; } }  ","version":"Next","tagName":"h2"},{"title":"Logging​","type":1,"pageTitle":"Configuration","url":"/dotnet/topics/configuration#logging","content":"Logging is provided by the external package Intility.Logging.AspNetCore in conjunction with logger sink extensions. The goal with the external package is to enable continuous development of logging support centrally, as the infrastructure changes over time, alleviating you of this burden. note For more information about logging configurations visit the Logging section. { &quot;Serilog&quot;: { &quot;MinimumLevel&quot;: { &quot;Default&quot;: &quot;Information&quot;, &quot;Override&quot;: { &quot;System&quot;: &quot;Warning&quot;, &quot;Microsoft&quot;: &quot;Warning&quot;, &quot;Microsoft.Hosting.Lifetime&quot;: &quot;Information&quot; } }, &quot;Properties&quot;: { &quot;Application&quot;: &quot;MyService&quot; } } }  ","version":"Next","tagName":"h2"},{"title":"Creating Logs​","type":1,"pageTitle":"Logging","url":"/dotnet/topics/logging#creating-logs","content":"To create logs, use an ILogger&lt;TCategoryName&gt; object from dependency injection (DI). Let's take a look at the following example: [ApiController] [Route(&quot;[controller]&quot;)] public class CustomerController : ControllerBase { private readonly ILogger _logger; public CustomerController(ILogger&lt;CustomerController&gt; logger) { _logger = logger; } [HttpPost] public ActionResult&lt;Customer&gt; Create(CreateCustomerDTO createCustomerDto) { _logger.LogInformation( &quot;Customer endpoint called at {Timestamp}&quot;, DateTime.UtcNow.ToLongTimeString()); //... } }  The DI system creates a logger and injects it into the controller. In this example the logger uses a log category of the fully qualified name of the type CustomerController. The log category is a string that is associated with each log entry and makes it easier to troubleshoot large quantities of logs. One can also observe that we are logging with the LogInformation extension method. Information is one of several log levels available - ordered by criticality: Debug:General debug information used in development environments with high verbosity Trace: Events related to code performance and infrastructure Information:Low criticality application information Warning:Medium criticality information and recoverable exceptions Error:Hight criticality information about non-recoverable exceptions and faulty states Critical:Severely critical messages related to crashes where the process cannot recover ","version":"Next","tagName":"h2"},{"title":"Docker-compose","type":0,"sectionRef":"#","url":"/fastapi/setup/docker-compose","content":"","keywords":"","version":"Next"},{"title":"Docker-compose​","type":1,"pageTitle":"Docker-compose","url":"/fastapi/setup/docker-compose#docker-compose","content":"info Only projects that are generated with SQLModel will will have a docker-compose.yaml file. docker-compose is configured to run docker images such as redis for your development server, and for tests. Before we can run these containers, we need to configure our environment variables. Head over to your .env file and fill in the remaining values (highlighted). These are only for development use, but it is still recommended to generate a secure password. danger Your password should not contain slashes (/), since these passwords are used in connection strings. You can generate passwords by using this command: openssl rand -hex 32. .env # Basics ENVIRONMENT=dev # Sentry SENTRY_DSN= # Authentication TENANT_ID=9b5ff18e-53c0-45a2-8bc2-9c0c8f60b2c6 APP_CLIENT_ID= OPENAPI_CLIENT_ID= # Only needed if you selected SQLModel POSTGRES_PASSWORD=  Then, run docker-compose: docker-compose up  ","version":"Next","tagName":"h3"},{"title":"Structured Logging​","type":1,"pageTitle":"Logging","url":"/dotnet/topics/logging#structured-logging","content":"In addition to the message we are also taking advantage of the structured logging capabilities baked into the logger. This means that we can inject arbitrary metadata surrounding our log events to make troubleshooting even easier. In the example above we are injecting the current timestamp into a property called Timestamp. Further more, we can also pass inn serializable objects like reference types or records. Serilog will automatically serialize the properties for you. Note that you have to prefix your property name with an @ symbol for this serialization to take place var albert = new { Name = &quot;Albert Aaberg&quot; }; logger.LogWarning(&quot;Could not find any friends of {@User}&quot;, albert);  ","version":"Next","tagName":"h2"},{"title":"Scoping​","type":1,"pageTitle":"Logging","url":"/dotnet/topics/logging#scoping","content":"It is sometimes useful to attach common metadata to a series of log events in your application instead of placing them separately in the log message itself. var props = new Dictionary&lt;string,object&gt;() { { &quot;Name&quot;, &quot;Albert Aaberg&quot;}, { &quot;Friends&quot;, 0 } }; using(logger.BeginScope(props)) { logger.LogInformation(&quot;Every log message inside this scope has metadata attached&quot;); } logger.LogInformation(&quot;The props has left the building&quot;);   ","version":"Next","tagName":"h2"},{"title":"Configure Logging​","type":1,"pageTitle":"Logging","url":"/dotnet/topics/logging#configure-logging","content":"With the serilog configuration it is possible to override the verbosity of the logs for each namespace separately. Very useful if you need to up the verbosity of your own code without clutter. NB: The overrides should always be stricter than the default MinimumLevel. There is also a very handy Properties section that lets you define custom metadata surrounding all your log events. The application host can also inject additional context to your logs through environment variables through the same configuration infrastructure. Configuration is usually provided by the Serilog section of the appsettings.{Environment}.json files. The following appsettings.json file is generated by the template. { &quot;Serilog&quot;: { &quot;MinimumLevel&quot;: { &quot;Default&quot;: &quot;Information&quot;, &quot;Override&quot;: { &quot;System&quot;: &quot;Warning&quot;, &quot;Microsoft&quot;: &quot;Warning&quot;, &quot;Microsoft.Hosting.Lifetime&quot;: &quot;Error&quot; } }, &quot;Properties&quot;: { &quot;Application&quot;: &quot;MyService&quot; } }  You can read more about logging at the official .NET Core documentation and by visiting the Serilog documentation for a complete overview of the configuration capabilities. Logging in .NET Core and ASP.NET Core~55 minutes to read ","version":"Next","tagName":"h2"},{"title":"Inspecting our OpenAPI docs","type":0,"sectionRef":"#","url":"/fastapi/setup/inspecting","content":"Inspecting our OpenAPI docs Now that we have a running application, we can head over and check out our OpenAPI documentation, and confirm that Azure AD Authentication works. Run the application, either throughpoetry or throughPyCharm. Head over to http://localhost:8000/docs. Here you'll see your API documentation, generated automatically frompydantic models. Try clicking on an API and try it out: As we can see, the response body is: { &quot;detail&quot;: &quot;Not authenticated&quot; } This is because this specific API view requires authentication. Click the Authorize button, leave the client_secret blank, and authorize. Log in through Azure AD, and try out the API again, and it should work. The next API, api/v1/hello-admin requires the user to have the AdminUser role. You can read more about roles in the official documentation, and how to lock down views on them in the FastAPI-Azure-Auth documentation.","keywords":"","version":"Next"},{"title":"Azure configuration","type":0,"sectionRef":"#","url":"/fastapi/setup/authorization","content":"","keywords":"","version":"Next"},{"title":"Backend API​","type":1,"pageTitle":"Azure configuration","url":"/fastapi/setup/authorization#backend-api","content":"","version":"Next","tagName":"h2"},{"title":"Step 1 - Create app registration​","type":1,"pageTitle":"Azure configuration","url":"/fastapi/setup/authorization#step-1---create-app-registration","content":"Head over toAzure -&gt; Azure Active Directory -&gt; App registrations, and create a new registration. Select a fitting name for your project; Azure will present the name to the user during consent. Supported account types: Single tenant - If you want to create a multi-tenant application, you should head over to the official documentationRedirect URI: Leave blank. Press Register  ","version":"Next","tagName":"h3"},{"title":"Step 2 - Change token version to v2​","type":1,"pageTitle":"Azure configuration","url":"/fastapi/setup/authorization#step-2---change-token-version-to-v2","content":"First we'll change the token version to version 2. In the left menu bar, click Manifest and find the line that says accessTokenAcceptedVersion. Change its value from null to 2. Press Save (This change can take some time to happen, which is why we do this first.)  ","version":"Next","tagName":"h3"},{"title":"Step 3 - Note down your application IDs​","type":1,"pageTitle":"Azure configuration","url":"/fastapi/setup/authorization#step-3---note-down-your-application-ids","content":"Go back to the Overview, found in the left menu. Copy the Application (Client) ID place it in your .env file: .env TENANT_ID=9b5ff18e-53c0-45a2-8bc2-9c0c8f60b2c6 APP_CLIENT_ID= OPENAPI_CLIENT_ID=   ","version":"Next","tagName":"h3"},{"title":"Step 4 - Add an application scope​","type":1,"pageTitle":"Azure configuration","url":"/fastapi/setup/authorization#step-4---add-an-application-scope","content":"Go to Expose an API in the left menu bar under your app registration.Press + Add a scopeYou'll be prompted to set an Application ID URI, leave the suggested one and press Save and continue  Add a scope named user_impersonation that can be consented by Admins and users. You can use the following descriptions: Access API as user Allows the app to access the API as the user. Access API as you Allows the app to access the API as you.   ","version":"Next","tagName":"h3"},{"title":"OpenAPI Documentation​","type":1,"pageTitle":"Azure configuration","url":"/fastapi/setup/authorization#openapi-documentation","content":"Our OpenAPI documentation will use the Authorization Code Grant Flow, with Proof Key for Code Exchange flow. It's a flow that enables a user of a Single-Page Application to safely log in, consent to permissions and fetch an access_tokenin the JWT format. When the user clicks Try out on the APIs, the access_token is attached to the header as a Bearer token. This is the token the backend will validate. So, let's set it up! ","version":"Next","tagName":"h2"},{"title":"Step 1 - Create app registration​","type":1,"pageTitle":"Azure configuration","url":"/fastapi/setup/authorization#step-1---create-app-registration-1","content":"Just like in the previous chapter, we have to create an application registration for our OpenAPI. Head over toAzure -&gt; Azure Active Directory -&gt; App registrations, and create a new registration. Use the same name, but with - OpenAPI appended to it. Supported account types: Single tenantRedirect URI: Choose Single-Page Application (SPA) and http://localhost:8000/oauth2-redirect as a value Press Register  ","version":"Next","tagName":"h3"},{"title":"Step 2 - Change token version to v2​","type":1,"pageTitle":"Azure configuration","url":"/fastapi/setup/authorization#step-2---change-token-version-to-v2-1","content":"Like last time, we'll change the token version to version 2. In the left menu bar, click Manifest and find the line that says accessTokenAcceptedVersion. Change its value from null to 2. Press Save  ","version":"Next","tagName":"h3"},{"title":"Step 3 - Note down your application IDs​","type":1,"pageTitle":"Azure configuration","url":"/fastapi/setup/authorization#step-3---note-down-your-application-ids-1","content":"Go back to the Overview, found in the left menu. Copy the Application (Client) ID and save it as your OPENAPI_CLIENT_ID: .env TENANT_ID=9b5ff18e-53c0-45a2-8bc2-9c0c8f60b2c6 APP_CLIENT_ID= OPENAPI_CLIENT_ID=   ","version":"Next","tagName":"h3"},{"title":"Step 4 - Allow OpenAPI to talk to the backend​","type":1,"pageTitle":"Azure configuration","url":"/fastapi/setup/authorization#step-4---allow-openapi-to-talk-to-the-backend","content":"To allow OpenAPI to talk to the backend API, you must add API permissions to the OpenAPI app registration. In the left menu, go to API Permissions and Add a permission.  Select the user_impersonation scope, and press Add a permission. Your view should now look something like this:  That's it! With these environment variables, FastAPI has been correctly configured from the template. ","version":"Next","tagName":"h3"},{"title":"Step 5 - Decide whether guest users should be allowed to access your application​","type":1,"pageTitle":"Azure configuration","url":"/fastapi/setup/authorization#step-5---decide-whether-guest-users-should-be-allowed-to-access-your-application","content":"You will most likely want to deny guest users, unless you have a very specific use case. Go to Azure AD -&gt; Enterprise Applications and find your application (you can search by Client ID). Under Properties, enable User assignment required? and save.  Then, go to Users and groups, and add user/group. Find users or a fitting group and assign it to the role Default Access. Read more about guest users here. ","version":"Next","tagName":"h3"},{"title":"Without PyCharm (poetry)","type":0,"sectionRef":"#","url":"/fastapi/setup/poetry","content":"","keywords":"","version":"Next"},{"title":"Virtual environment​","type":1,"pageTitle":"Without PyCharm (poetry)","url":"/fastapi/setup/poetry#virtual-environment","content":"There are two options for creating your virtual environment, either manually through poetry or PyCharm. info This section will cover how to use poetry. Head over to the previous page if you want to use PyCharm instead. ","version":"Next","tagName":"h2"},{"title":"Creating a virtual environment​","type":1,"pageTitle":"Without PyCharm (poetry)","url":"/fastapi/setup/poetry#creating-a-virtual-environment","content":"info Its easier to deal with poetry when the virtual environment is placed in your working directory. You can configure poetry to do this by issuing this command: poetry config virtualenvs.in-project true  First create a virtual environment and install dependencies: poetry update  The update command both updates the poetry.lock file and creates the virtual environment. Activate your new virtual environment: poetry shell  ","version":"Next","tagName":"h3"},{"title":"Migrations​","type":1,"pageTitle":"Without PyCharm (poetry)","url":"/fastapi/setup/poetry#migrations","content":"You can skip this section if you didn't select sqlmodel and have a database. In order to configure the database tables to reflect your models, you must run migrations. In this project, we use alembic to manage our migrations. Running migrations is done through the terminal: alembic upgrade head  ","version":"Next","tagName":"h3"},{"title":"Running the server​","type":1,"pageTitle":"Without PyCharm (poetry)","url":"/fastapi/setup/poetry#running-the-server","content":"With your virtual environment activated and docker-compose running, we can run our server. poetry run uvicorn app.main:app --host localhost --port 8000 --reload  ","version":"Next","tagName":"h3"},{"title":"GitLab Repository","type":0,"sectionRef":"#","url":"/fastapi/setup/gitlab","content":"","keywords":"","version":"Next"},{"title":"Pushing your application​","type":1,"pageTitle":"GitLab Repository","url":"/fastapi/setup/gitlab#pushing-your-application","content":"Creating a FastAPI project from a template does not automatically create a git repository for you, so we have to make one ourselves. pre-commit Remember, we use pre-commit, so we'll have to initiate that before we try to commit! Follow the &quot;Push an existing folder&quot; example, but mix in pre-commit. The commands should look like this: git init git remote add origin git@gitlab.intility.no:Group/intility-api.git git checkout -b main pre-commit install # &lt;--- This is an important step git add . git commit -m &quot;Initial commit&quot;  Sometimes checks will fail, or some files might be modified (by e.g. black). When this happens, add the modified files and try again: git add . git commit -m &quot;Initial commit&quot; git push origin main  Later, when you have made changes to your code, other checks may fail. These checks can be anything from missing docstrings, leftover prints etc. If you want to ignore checks, you can typically do so globally in the configuration files, or the line where the check fail. How to configure these checks will vary, so spend some time to get familiar with the tools. If you want to ignore pre-commit checks, you can use the --no-verify flag when committing: git add . git commit -m &quot;Initial commit&quot; --no-verify  ","version":"Next","tagName":"h2"},{"title":"Using PyCharm","type":0,"sectionRef":"#","url":"/fastapi/setup/pycharm","content":"","keywords":"","version":"Next"},{"title":"Virtual environment​","type":1,"pageTitle":"Using PyCharm","url":"/fastapi/setup/pycharm#virtual-environment","content":"There are two options for creating your virtual environment, either manually through poetry or PyCharm. info This section will cover how to use PyCharm. Head over to the next page if you want to use poetry instead. ","version":"Next","tagName":"h2"},{"title":"Creating a virtual environment​","type":1,"pageTitle":"Using PyCharm","url":"/fastapi/setup/pycharm#creating-a-virtual-environment","content":"Open PyCharm settings and search for interpreter  Create a new interpreter from your Python:  Open a new terminal in PyCharm (it will automatically be activated and install the dependencies: poetry update  The update command both updates the poetry.lock file and installs the dependencies. ","version":"Next","tagName":"h3"},{"title":"Migrations​","type":1,"pageTitle":"Using PyCharm","url":"/fastapi/setup/pycharm#migrations","content":"You can skip this section if you didn't select sqlmodel and have a database. In order to configure the database tables to reflect your models, you must run migrations. In this project, we use alembic to manage our migrations. Running migrations is done through the terminal: alembic upgrade head  ","version":"Next","tagName":"h3"},{"title":"Configuring PyCharm to run the server​","type":1,"pageTitle":"Using PyCharm","url":"/fastapi/setup/pycharm#configuring-pycharm-to-run-the-server","content":"Configure PyCharm to use uvicorn locally, pointing to your FastAPI application. It's important to run this on localhost:8000 and not 127.0.0.1:8000 for OpenAPI authentication to work properly. The --reload flag will ensure the server is restarted on every file change in the app folder. First, click the drop down in the top right corner.  Click the + sign and select Python.   Then configure PyCharm: Name: ServerModule name: uvicornParameters: app.main:app --host localhost --port 8000 --reloadPython interpreter: The one you created earlierWorking directory: Your current directory  Click OK to save and exit. Run the server. info Remember to run docker-compose before attempting to run your server. ","version":"Next","tagName":"h3"},{"title":"React","type":0,"sectionRef":"#","url":"/react/","content":"","keywords":"","version":"Next"},{"title":"Vite​","type":1,"pageTitle":"React","url":"/react/#vite","content":"Vite is the main part of the development environment, these docs only covers the Intility template part of it. This means that everything from the official Vite docs applies to your project. If you can't find what your looking for here, check the Vite docs. ","version":"Next","tagName":"h2"},{"title":"Recommended reading​","type":1,"pageTitle":"React","url":"/react/#recommended-reading","content":"Environment VariablesConfiguring Vite ","version":"Next","tagName":"h3"},{"title":"Testing","type":0,"sectionRef":"#","url":"/fastapi/topics/testing","content":"Testing Testing is important. Your app is shipped with a tests folder, which contains a bunch of example tests. In order to understand them, you should read these resources: Official docs on testingOfficial docs on testing a databaseOfficial docs on async tests And lastly, learn about pytest, specifically how conftest.py and fixtures work. You can do so here: Official docs on pytest fixturesOfficial docs on pytest conftest.py When running tests, remember to first run your containers by running docker-compose up. You can now run pytest through poetry: poetry run pytest . --cov You can also run tests through PyCharm. Right click your tests folder and click Run 'pytest in tests'. If you're facing issues, click the dropdown in the top right corner and ensure the tests are run from your root folder.","keywords":"","version":"Next"},{"title":"SQLmodel and migrations","type":0,"sectionRef":"#","url":"/fastapi/topics/migrations","content":"SQLmodel and migrations If you selected SQLModel you should do the official tutorial before making changes. When you create or change a SQLModel in Python, the database needs to be updated as well. We do this by generating (and potentially manually edit) migration files. This project has been shipped withalembic based on the testdriven.io tutorial.","keywords":"","version":"Next"},{"title":"Sentry","type":0,"sectionRef":"#","url":"/fastapi/setup/sentry","content":"","keywords":"","version":"Next"},{"title":"Create Project​","type":1,"pageTitle":"Sentry","url":"/fastapi/setup/sentry#create-project","content":"Head over to the Create a new Project page in Sentry. Under platform, select ASGI  For the project name, use the project slug from GitLab. Select a fitting team, or create a new one, and hit Create. You'll be taken to a Configure ASGI page. In the code examples, copy the DSN value passed to sentry_sdk.init, and add it to your .env file under SENTRY_DSN: .env # Basics ENVIRONMENT=dev # Sentry SENTRY_DSN= # Authentication TENANT_ID=9b5ff18e-53c0-45a2-8bc2-9c0c8f60b2c6 APP_CLIENT_ID= OPENAPI_CLIENT_ID= # Databases, cache etc. # Only needed if you selected SQLModel POSTGRES_PASSWORD=  ","version":"Next","tagName":"h2"},{"title":"Adding Environments","type":0,"sectionRef":"#","url":"/react/advanced/adding-environments","content":"","keywords":"","version":"Next"},{"title":"Enabling the deploy:prod job​","type":1,"pageTitle":"Adding Environments","url":"/react/advanced/adding-environments#enabling-the-deployprod-job","content":"The provided deploy:prod job is disabled by default. This is to force you to make an active choice on wether you want to use the job or ArgoCD. To enable the job, simply remove the . from the last job. .gitlab-ci.yml - .deploy:prod: + deploy:prod:  ","version":"Next","tagName":"h2"},{"title":"Trigger production jobs​","type":1,"pageTitle":"Adding Environments","url":"/react/advanced/adding-environments#trigger-production-jobs","content":"To trigger the production jobs, simply run npm version [major|minor|patch] git push --tags  This will update the version field in package.json, update the appVersion field in chart/Chart.yaml, and create a git tag with the version. After all the other jobs has completed, we can manually trigger the deploy:prod job. This is manual by design, and shouldn't be set to automatic. ","version":"Next","tagName":"h3"},{"title":"Separate OpenShift project​","type":1,"pageTitle":"Adding Environments","url":"/react/advanced/adding-environments#separate-openshift-project","content":"You can, and should create a separate OpenShift project to host the production environment. To do this, simply follow the same steps as earlier. This time, name it aa-&lt;project-slug&gt;-prod. When adding the OPENSHIFT_TOKEN to CI/CD variables, select prod as the Environment scope. This variable will then be used instead of the default one in the deploy:prod job.  note If you can't see the prod environment when creating a variable, you need to trigger the production jobs first. The build:prod job will then provision the prod environment, and you can insert the OPENSHIFT_TOKEN before triggering the deploy job. ","version":"Next","tagName":"h3"},{"title":"Adding even more Environments​","type":1,"pageTitle":"Adding Environments","url":"/react/advanced/adding-environments#adding-even-more-environments","content":"Usually, a development and a production environment is enough. In big applications however, you might see the need for more environments. In this example, we will set up a QA environment. To do this, we will simply copy the prod jobs, and create our own for qa instead. .gitlab-ci.yml build:qa: extends: build:dev environment: name: qa rules: - if: '$CI_COMMIT_TAG' image:qa: extends: image:dev variables: IMAGE_TAG: qa rules: - if: '$CI_COMMIT_TAG' needs: ['build:qa'] sentry:qa: extends: sentry:dev variables: SENTRY_ENV: qa rules: - if: '$CI_COMMIT_TAG' needs: ['build:qa'] .deploy:qa: extends: deploy:dev variables: ROUTE: $CI_PROJECT_NAME-qa.apps.int.intility.no environment: name: qa url: https://$CI_PROJECT_NAME-qa.apps.int.intility.no rules: - if: '$CI_COMMIT_TAG' needs: ['test', 'image:qa']  note We don't override the Sentry release and the image version, to avoid version collisions with the production jobs. This example will, like the production jobs, be triggered by git tags. But it will automatically deploy it to the QA environment, which will be created in the default OpenShift project, unless you've created a custom QA project. ","version":"Next","tagName":"h2"},{"title":"Environment Variables","type":0,"sectionRef":"#","url":"/react/configuration/environment-variables","content":"Environment Variables Your project can consume variables declared in your environment as if they were declared locally in your JS files. By default you will have import.meta.env.MODE defined for you, and any other environment variables starting with VITE_. By default, a .env.development file is included, which will be loaded when you run your app locally. For more information, please read the Env Variables and Modes section of the Vite docs.","keywords":"","version":"Next"},{"title":"Deploy","type":0,"sectionRef":"#","url":"/react/configuration/deploy","content":"","keywords":"","version":"Next"},{"title":"Create project​","type":1,"pageTitle":"Deploy","url":"/react/configuration/deploy#create-project","content":"UICLI Go to our OpenShift instance and log in as Intility Developer. Create a project, the name should be aa-&lt;GITLAB_SLUG&gt;-dev, e.g. aa-my-app-dev. Add a fitting display name and description if you feel like it. ","version":"Next","tagName":"h2"},{"title":"Acquire Token​","type":1,"pageTitle":"Deploy","url":"/react/configuration/deploy#acquire-token","content":"UICLI In your newly created project, switch from Developer to Administrator view in the sidebar. Then go to User Management -&gt; Service Accounts, and click Create Service Account. Change the name field to gitlab-builder. After creating the Service Account, go to User Mangement -&gt; Role Bindings, and click Create Binding. Fill the form with the following values: Role Binding Name: gitlab-builder-edit Role Name: edit Subject: Service Account Subject Name: gitlab-builder After creating the role binding, go back to Service Accounts and go to the gitlab-builder Service Account. At the bottom of page, you'll find a link to a secret named gitlab-builder-token-*, click it. Copy the token field at the bottom of the page, and add it to GitLab CI/CD variables with the key OPENSHIFT_TOKEN. ","version":"Next","tagName":"h2"},{"title":"Deploy with ArgoCD","type":0,"sectionRef":"#","url":"/react/advanced/deploy-argocd","content":"Deploy with ArgoCD info This page isn't finished yet. If you are comfortable with this subject, feel free to contribute.","keywords":"","version":"Next"},{"title":"Sentry","type":0,"sectionRef":"#","url":"/react/configuration/sentry","content":"","keywords":"","version":"Next"},{"title":"Create Project​","type":1,"pageTitle":"Sentry","url":"/react/configuration/sentry#create-project","content":"Head over to the Create a new Project page in Sentry.  Under platform, select React.  For the project name, use the project slug from GitLab. Select a fitting team, or create a new one, and hit Create. note If you use something other than the GitLab project slug you'll need to modify the SENTRY_PROJECT variable in the top of the .gitlab-ci.yml file. You'll be taken to a Configure React page. In the code example under Connecting the SDK to Sentry, copy the dsn value, and add it to GitLab CI/CD variables with the key SENTRY_DSN. ","version":"Next","tagName":"h3"},{"title":"Acquire Token​","type":1,"pageTitle":"Sentry","url":"/react/configuration/sentry#acquire-token","content":"Go to the Auth Token section of your Account Settings. The needed scopes are project:read, project:releases and org:read. Create it, copy the token and add it to GitLab CI/CD variables with the key SENTRY_AUTH_TOKEN. ","version":"Next","tagName":"h3"},{"title":".gitlab-ci.yml Overview","type":0,"sectionRef":"#","url":"/react/configuration/gitlab-ci","content":"","keywords":"","version":"Next"},{"title":"build​","type":1,"pageTitle":".gitlab-ci.yml Overview","url":"/react/configuration/gitlab-ci#build","content":"The main build job runs vite build on every push to all branches (except master). It will pass some default environment variables; VITE_SENTRY_DSN will be SENTRY_ENVVITE_SENTRY_ENVIRONMENT will be the git branch nameVITE_SENTRY_RELEASE will be the git commit SHA It also creates an artifact of the build folder that is created, which will be passed onto later jobs. The build:* pipeline does the same as build, except it adds a GitLab environment. The base job uses the GitLab environment name to configure the Sentry environment. ","version":"Next","tagName":"h2"},{"title":"image​","type":1,"pageTitle":".gitlab-ci.yml Overview","url":"/react/configuration/gitlab-ci#image","content":"The image jobs builds a docker image with the Dockerfile.CI dockerfile, and with the build output from the build jobs. For the image:dev job, it pushes two tags, one with dev, and one with the pipeline id. For the image:prod job, the tags pushed are latest and the tag name. ","version":"Next","tagName":"h2"},{"title":"sentry​","type":1,"pageTitle":".gitlab-ci.yml Overview","url":"/react/configuration/gitlab-ci#sentry","content":"The sentry job uses the Sentry CLI to create a new release. The release name will be the git commit SHA. It will connect the release to the current commit, and upload sourcemaps from the build step. Lastly it will associate the release with the right env. ","version":"Next","tagName":"h2"},{"title":"deploy​","type":1,"pageTitle":".gitlab-ci.yml Overview","url":"/react/configuration/gitlab-ci#deploy","content":"This is the main job for deploying to OpenShift. It will create an environment in GitLab, with the URL to the running app. It uses Helm to install the app to an OpenShift project. For deploy:dev, the route defaults to https://{projectSlug}-dev.apps.int.intility.no. For deploy:prod, the route defaults to https://{projectSlug}.apps.int.intility.no. ","version":"Next","tagName":"h2"},{"title":"GitLab Repository","type":0,"sectionRef":"#","url":"/react/configuration/gitlab","content":"","keywords":"","version":"Next"},{"title":"Pushing your application​","type":1,"pageTitle":"GitLab Repository","url":"/react/configuration/gitlab#pushing-your-application","content":"Creating a dotnet project from a template does not automatically create a git repository for you, so we have to make one ourselves. Follow the &quot;Push an existing folder&quot; example, which should look something like this: git init --initial-branch=main git remote add origin git@gitlab.intility.com:Group/intility-app.git git add . git commit -m &quot;Initial commit&quot; git push -u origin main  The pipeline will fail initially, but don't worry, we'll set it up correctly in the next steps. ","version":"Next","tagName":"h2"},{"title":"Add GitLab Deploy Token​","type":1,"pageTitle":"GitLab Repository","url":"/react/configuration/gitlab#add-gitlab-deploy-token","content":"The pipeline publishes a docker image to GitLab Container Registry, and uses Helm to create resources in OpenShift. As a result, OpenShift needs access to pull images from GCR. In your GitLab repository, go to Settings -&gt; Repository -&gt; Deploy tokens. Create a new token named gitlab-deploy-token, and give it the read_registry scope.  That's all you have to do in the repository. The token is exposed as a variable in the pipeline, and helm applies it as a pull secret in OpenShift. Read more about GitLab deploy tokens here. ","version":"Next","tagName":"h2"},{"title":"Adding CI/CD Variables​","type":1,"pageTitle":"GitLab Repository","url":"/react/configuration/gitlab#adding-cicd-variables","content":"In your project on GitLab, go to Settings -&gt; CI / CD, and expand the Variables section. We don't need to add anything yet, but it's here we'll add tokens and such in the other steps. ","version":"Next","tagName":"h2"},{"title":"Adding Badges​","type":1,"pageTitle":"GitLab Repository","url":"/react/configuration/gitlab#adding-badges","content":"In your project on GitLab, go to Settings -&gt; General, and expand the Badges section. Here you can add badges by giving them a Name, Link and Image URL.  We can go ahead and add a badge for our pipeline with the following values: Name: Pipeline Link: https://gitlab.intility.com/%{project_path} Image URL: https://gitlab.intility.com/%{project_path}/badges/%{default_branch}/pipeline.svg ","version":"Next","tagName":"h2"},{"title":"Included Dependencies","type":0,"sectionRef":"#","url":"/react/getting-started/included-dependencies","content":"","keywords":"","version":"Next"},{"title":"@intility/bifrost-react​","type":1,"pageTitle":"Included Dependencies","url":"/react/getting-started/included-dependencies#intilitybifrost-react","content":"Docs Intility's design system for React. ","version":"Next","tagName":"h2"},{"title":"@azure/msal-*​","type":1,"pageTitle":"Included Dependencies","url":"/react/getting-started/included-dependencies#azuremsal-","content":"@azure/msal-react Docs@azure/msal-browser Docs Authentication libraries. ","version":"Next","tagName":"h2"},{"title":"react-router​","type":1,"pageTitle":"Included Dependencies","url":"/react/getting-started/included-dependencies#react-router","content":"Docs Unless you're a dashboard, you need a router, and react-router is the de facto router for React. ","version":"Next","tagName":"h2"},{"title":"@sentry/react and @sentry/tracing​","type":1,"pageTitle":"Included Dependencies","url":"/react/getting-started/included-dependencies#sentryreact-and-sentrytracing","content":"Docs Used for error reporting to Sentry. ","version":"Next","tagName":"h2"},{"title":"prettier​","type":1,"pageTitle":"Included Dependencies","url":"/react/getting-started/included-dependencies#prettier","content":"Docs Prettier is a code formatter and great tool for unifying formatting when collaborating on a project. The Visual Studio Code Workspace is set up to auto-format on save. ","version":"Next","tagName":"h2"},{"title":"Recommended Packages","type":0,"sectionRef":"#","url":"/react/getting-started/recommended-packages","content":"","keywords":"","version":"Next"},{"title":"react-table​","type":1,"pageTitle":"Recommended Packages","url":"/react/getting-started/recommended-packages#react-table","content":"Docs Data modification for tables. Bifrost's Table component is only responsible for the view, and will not do any data modification for you. ","version":"Next","tagName":"h2"},{"title":"swr​","type":1,"pageTitle":"Recommended Packages","url":"/react/getting-started/recommended-packages#swr","content":"Docs Data Fetching library using React hooks. Makes data fetching easy, comes with a cache, Suspense support and more. ","version":"Next","tagName":"h2"},{"title":"Project Overview","type":0,"sectionRef":"#","url":"/react/getting-started/project-overview","content":"Project Overview Depending on which template you chose, your project structure will look more or less like the following: ├── .vscode │ ├── extensions.json │ └── settings.json ├── chart │ ├── templates │ │ ├── _helpers.tpl │ │ ├── config.yaml │ │ ├── deployment.yaml │ │ ├── pull-secret.yaml │ │ ├── route.yaml │ │ ├── secrets.yaml │ │ └── service.yaml │ ├── Chart.yaml │ └── values.yaml ├── public │ ├── favicon.ico │ ├── logo192.png │ ├── logo512.png │ ├── manifest.json │ └── robots.txt ├── src │ ├── assets │ │ ├── react.svg │ │ └── vite.svg │ ├── auth │ │ ├── authorizedFetch.ts │ │ ├── config.ts │ │ ├── index.ts │ │ └── instance.ts │ ├── components │ │ ├── About.tsx │ │ ├── ErrorPage.tsx │ │ ├── Home.css │ │ ├── Home.test.tsx │ │ ├── Home.tsx │ │ ├── Navigation.tsx │ │ └── Profile.tsx │ ├── utils │ │ └── initializeSentry.ts │ ├── index.tsx │ ├── router.tsx │ ├── setupTests.ts │ └── vite-env.d.ts ├── Dockerfile ├── Dockerfile.CI ├── README.md ├── index.html ├── package.json ├── tsconfig.json ├── tsconfig.node.json └── vite.config.ts ","keywords":"","version":"Next"},{"title":"Installation","type":0,"sectionRef":"#","url":"/react/getting-started/installation","content":"","keywords":"","version":"Next"},{"title":"Prerequisites​","type":1,"pageTitle":"Installation","url":"/react/getting-started/installation#prerequisites","content":"Some experience with Reactnode.jsVisual Studio Code with the following plugins Node Extension PackPrettier ","version":"Next","tagName":"h2"},{"title":"Create App​","type":1,"pageTitle":"Installation","url":"/react/getting-started/installation#create-app","content":"Run these commands in your terminal. npx degit intility/templates/react my-app cd my-app npm install  Open the project folder in Visual Studio Code with the following command. code .  You can now start coding by running the start script. npm start  info The template includes a .npmrc config which sets up a custom registry for @intility/* and @fortawesome/* packages. For alternative package registry setup, see the NPM docs in Backstage. ","version":"Next","tagName":"h2"},{"title":"Available Scripts​","type":1,"pageTitle":"Installation","url":"/react/getting-started/installation#available-scripts","content":"There are 5 scripts included by default, click on each one for more information. npm startnpm testnpm run buildnpm run previewnpm run analyze ","version":"Next","tagName":"h2"},{"title":"AAD Authentication","type":0,"sectionRef":"#","url":"/react/configuration/authentication","content":"","keywords":"","version":"Next"},{"title":"Create App Registration​","type":1,"pageTitle":"AAD Authentication","url":"/react/configuration/authentication#create-app-registration","content":"Head over to Azure -&gt; Azure Active Directory -&gt; App registrationswith your Intility Account, and create a new registration.  Select a fitting name for your project, this name will be presented to the user during consent. Under Supported account types, choose either Intility AS only - Single tenant or Any Azure AD directory - Multitenant. This can be changed later, so if you're unsure what to choose, select single tenant. Under Redirect URI, select Single-page application (SPA) from the dropdown, and enter http://localhost:3000. Hit the register button, and you will be taken to an overview of your newly created registration.  Copy the Application (Client) ID GUID, and paste it into the clientId field in your auth/config.ts file. src/auth/config.ts const msal = { auth: { clientId: &quot;YOUR_CLIENT_ID&quot;, ... }, ... }  Check out Enabling authentication in your app to enable authentication in your app. ","version":"Next","tagName":"h3"},{"title":"Adding reply URLs​","type":1,"pageTitle":"AAD Authentication","url":"/react/configuration/authentication#adding-reply-urls","content":"For each deployment of your app, you'll need to register it. You can do that by going to the Authentication page.  The first we need to add is the URL the deploy step makes in OpenShift: https://{your-project-slug}-dev.apps.int.intility.no  You can also add more later if you create more environments. ","version":"Next","tagName":"h3"},{"title":"Enabling authentication in your app​","type":1,"pageTitle":"AAD Authentication","url":"/react/configuration/authentication#enabling-authentication-in-your-app","content":"Depending on what your applications scope is, there are different ways of enabling authentication. ","version":"Next","tagName":"h2"},{"title":"Forcing auth​","type":1,"pageTitle":"AAD Authentication","url":"/react/configuration/authentication#forcing-auth","content":"This is the simplest way, and can be enabled by wrapping your application in MsalAuthenticationTemplate from @azure/msal-react. src/index.tsx root.render( &lt;React.StrictMode&gt; &lt;MsalProvider instance={instance}&gt; &lt;MsalAuthenticationTemplate interactionType={InteractionType.Redirect} authenticationRequest={{ scopes: ['User.Read'] }} &gt; &lt;RouterProvider router={router} /&gt; &lt;/MsalAuthenticationTemplate&gt; &lt;/MsalProvider&gt; &lt;/React.StrictMode&gt;, );  This will force user authentication, and your app won't render unless the user is authenticated. ","version":"Next","tagName":"h3"},{"title":"Other methods​","type":1,"pageTitle":"AAD Authentication","url":"/react/configuration/authentication#other-methods","content":"There are many ways to protect your application, both conditionally and forced. Read the @azure/msal-react docs to see other ways to authenticate. ","version":"Next","tagName":"h3"},{"title":"Consuming an authenticated API​","type":1,"pageTitle":"AAD Authentication","url":"/react/configuration/authentication#consuming-an-authenticated-api","content":"To consume an authenticated API you will need to add permission. You can do this by going to your frontends application registration in Azure, under API Permissions. Click &quot;Add a permission&quot; and follow the steps to add the api scope you need. The permission you add will have a scope looking something like api://application-guid/scopename, which you will use as the 'API_SCOPE' variable in the next steps below.  If the API you want to consume requires user consent you'll need to add the api scope to the authenticationRequest scopes. src/index.tsx root.render( &lt;React.StrictMode&gt; &lt;MsalProvider instance={instance}&gt; &lt;MsalAuthenticationTemplate interactionType={InteractionType.Redirect} authenticationRequest={{ scopes: ['User.Read', 'API_SCOPE'] }} &gt; &lt;RouterProvider router={router} /&gt; &lt;/MsalAuthenticationTemplate&gt; &lt;/MsalProvider&gt; &lt;/React.StrictMode&gt;, );  You'll also need to modify the authorizedFetch method, and acquire the correct scopes for the URL you're trying to call. src/auth/authorizedFetch.ts async function authorizedFetch() { ... if (url?.toLowerCase().startsWith('https://graph.microsoft.com')) { scopes.push('User.Read'); } else if (url?.toLowerCase().startsWith('http://localhost:5000')) { scopes.push('API_SCOPE'); } ... }  The API base URL can also be dynamically applied from an Environment Variables. src/auth/authorizedFetch.ts async function authorizedFetch() { ... if (url?.toLowerCase().startsWith('https://graph.microsoft.com')) { scopes.push('User.Read'); } else if (url?.toLowerCase().startsWith(import.meta.env.VITE_API_URL)) { scopes.push('API_SCOPE'); } ... }  You can now consume an API with authorizedFetch, which uses the endpoints config to detect which token to use in a request. import { useState, useEffect } from 'react'; import { authorizedFetch } from '~/auth'; // This is a simplified example of data fetching in react // Please don't use in production const DataComponent = () =&gt; { const [data, setData] = useState(); const [error, setError] = useState(); useEffect(() =&gt; { authorizedFetch('my-api/resource') .then((response) =&gt; response.json()) .then((json) =&gt; setData(json)) .catch((error) =&gt; setError(error)); }, []); return ( &lt;&gt; {!data &amp;&amp; !error &amp;&amp; &lt;p&gt;Loading data...&lt;/p&gt;} {data &amp;&amp; &lt;div&gt;Here is the data: {data}&lt;/div&gt;} {error &amp;&amp; &lt;p className=&quot;error&quot;&gt;Oh No!!! {error.toString()}&lt;/p&gt;} &lt;/&gt; ); };  ","version":"Next","tagName":"h2"},{"title":"SWR / React Query​","type":1,"pageTitle":"AAD Authentication","url":"/react/configuration/authentication#swr--react-query","content":"SWRReact Query Before continuing this step, read about and install SWR. Integrating authenticatedFetch with SWR is very simple. All you need to do is specify a fetcher for SWR. import useSWR from 'swr'; import { authorizedFetch } from '~/auth'; const authFetcher = (url: string) =&gt; authorizedFetch(url).then((result) =&gt; result.json()); const SwrComponent = () =&gt; { const { data, error } = useSWR('my-api/resource', { fetcher: authFetcher }); return ( &lt;&gt; {!data &amp;&amp; !error &amp;&amp; &lt;p&gt;Loading data...&lt;/p&gt;} {data &amp;&amp; &lt;div&gt;Here is the data: {data}&lt;/div&gt;} {error &amp;&amp; &lt;p className=&quot;error&quot;&gt;Oh No!!! {error.toString()}&lt;/p&gt;} &lt;/&gt; ); }; We could take this one step further, and assign the fetcher globally using SWRConfig. src/index.tsx import { SWRConfig } from 'swr'; import { authorizedFetch } from '~/auth'; // Note that we apply a base url to every request const swr = { fetcher: (path: string) =&gt; authorizedFetch(import.meta.env.VITE_API_URL + path).then((response) =&gt; response.json(), ), }; root.render( &lt;React.StrictMode&gt; &lt;MsalProvider instance={instance}&gt; &lt;SWRConfig value={swr}&gt; &lt;RouterProvider router={router} /&gt; &lt;/SWRConfig&gt; &lt;/MsalProvider&gt; &lt;/React.StrictMode&gt;, ); We can now call useSWR somewhere in our app, and it will by default use the authorized fetcher. import useSWR from 'swr'; import { authorizedFetch } from '~/auth'; const SwrComponent = () =&gt; { // Note that only the resource is requested here // that's because the API base URL is prepended in our fetcher const { data, error } = useSWR('resource'); return ( &lt;&gt; {!data &amp;&amp; !error &amp;&amp; &lt;p&gt;Loading data...&lt;/p&gt;} {data &amp;&amp; &lt;div&gt;Here is the data: {data}&lt;/div&gt;} {error &amp;&amp; &lt;p className=&quot;error&quot;&gt;Oh No!!! {error.toString()}&lt;/p&gt;} &lt;/&gt; ); }; One great thing about SWR is request deduping and caching. In the following example, there will be three instances of our SwrComponent, but only one request will be made. That would not be the case if we were to use the DataComponent from earlier, where we manually fetched the data. const SomeExample = () =&gt; ( &lt;&gt; &lt;SwrComponent /&gt; &lt;SwrComponent /&gt; &lt;SwrComponent /&gt; &lt;/&gt; ); To read more about SWR, check out the SWR Docs. ","version":"Next","tagName":"h3"}],"options":{"id":"default"}}